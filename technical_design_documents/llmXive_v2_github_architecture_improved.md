# llmXive v2.0: Improved GitHub-Based Architecture

**Project ID**: LLMX-2024-001-WEB-IMPROVED  
**Date**: 2025-07-06  
**Status**: Design Phase - Final  
**Contributors**: Claude (Sonnet 4), Jeremy Manning, Gemini (Expert Review)  

## Overview

This document presents a refined GitHub-based architecture for llmXive v2.0 that addresses critical technical concerns identified in the expert review. The improved design maintains the zero-cost, web-based approach while adding robust error handling, performance optimizations, and enhanced security.

## Key Improvements

### 1. **Robust Rate Limiting and Caching**
- Intelligent request batching and queuing
- Multi-layer caching strategy (browser, localStorage, GitHub)
- GraphQL API usage for efficient data fetching
- Graceful degradation when rate limits hit

### 2. **Improved Repository Management**
- Git LFS integration for large files
- Atomic repository operations with rollback
- Simplified splitting logic with better error handling
- Background monitoring and maintenance

### 3. **Enhanced Security**
- Proper OAuth PKCE flow implementation
- Secure token management with automatic refresh
- Comprehensive input validation
- Protection against common web vulnerabilities

### 4. **Performance Optimizations**
- Server-side dependency resolution via GitHub Actions
- Progressive loading for large datasets
- Service worker for offline capability
- Background synchronization

## Architecture Overview

### Core Components

```
llmXive v2.0 Improved Architecture
â”œâ”€â”€ Web Application (GitHub Pages)
â”‚   â”œâ”€â”€ Core Engine (client-side)
â”‚   â”œâ”€â”€ UI Components (reactive)
â”‚   â”œâ”€â”€ Service Worker (offline support)
â”‚   â””â”€â”€ Cache Management (multi-layer)
â”œâ”€â”€ GitHub Actions (server-side processing)
â”‚   â”œâ”€â”€ Dependency Resolution
â”‚   â”œâ”€â”€ Project Orchestration
â”‚   â”œâ”€â”€ Repository Management
â”‚   â””â”€â”€ Data Validation
â”œâ”€â”€ Storage Strategy
â”‚   â”œâ”€â”€ Main Repository (metadata + small projects)
â”‚   â”œâ”€â”€ Git LFS (large files in main repo)
â”‚   â”œâ”€â”€ Separate Repositories (only for massive projects >1GB)
â”‚   â””â”€â”€ Cache Storage (browser + GitHub releases)
â””â”€â”€ Security Layer
    â”œâ”€â”€ OAuth PKCE Flow
    â”œâ”€â”€ Token Management
    â”œâ”€â”€ Input Validation
    â””â”€â”€ Rate Limiting
```

## Improved Repository Strategy

### 1. **Git LFS First Approach**

Instead of splitting repositories at 100MB, use Git LFS for large files:

```yaml
# .gitattributes
*.csv filter=lfs diff=lfs merge=lfs -text
*.h5 filter=lfs diff=lfs merge=lfs -text
*.pkl filter=lfs diff=lfs merge=lfs -text
*.npz filter=lfs diff=lfs merge=lfs -text
*.pdf filter=lfs diff=lfs merge=lfs -text
*.png filter=lfs diff=lfs merge=lfs -text
*.jpg filter=lfs diff=lfs merge=lfs -text
*.mp4 filter=lfs diff=lfs merge=lfs -text
```

### 2. **Simplified Repository Structure**

```
llmXive/
â”œâ”€â”€ docs/                          # GitHub Pages application
â”œâ”€â”€ projects/                      # All projects (using Git LFS for large files)
â”‚   â”œâ”€â”€ PROJ-001-small/
â”‚   â”œâ”€â”€ PROJ-002-large-with-lfs/   # Uses Git LFS for large files
â”‚   â””â”€â”€ PROJ-003-huge/             # Only split if >1GB total
â”œâ”€â”€ separate-repos/                # Only for truly massive projects
â”‚   â””â”€â”€ PROJ-003-huge -> submodule to llmXive-PROJ-003-huge
â”œâ”€â”€ cache/                         # Cached data for performance
â”‚   â”œâ”€â”€ dependency-graphs/
â”‚   â”œâ”€â”€ project-registry/
â”‚   â””â”€â”€ api-responses/
â””â”€â”€ .github/
    â””â”€â”€ workflows/                 # Server-side processing
```

## Enhanced Web Application

### 1. **Intelligent GitHub Client**

```javascript
class EnhancedGitHubClient {
    constructor() {
        this.baseUrl = 'https://api.github.com';
        this.graphqlUrl = 'https://api.github.com/graphql';
        this.token = null;
        
        // Rate limiting
        this.rateLimitManager = new RateLimitManager();
        this.requestQueue = new RequestQueue();
        
        // Caching
        this.cache = new MultiLayerCache();
        
        // Security
        this.tokenManager = new SecureTokenManager();
    }
    
    async initialize() {
        // Initialize secure authentication
        await this.tokenManager.initialize();
        this.token = await this.tokenManager.getValidToken();
        
        // Set up request interception for caching
        this.setupRequestInterception();
    }
    
    async apiRequest(endpoint, options = {}) {
        // Check cache first
        const cacheKey = this.generateCacheKey(endpoint, options);
        const cached = await this.cache.get(cacheKey);
        
        if (cached && !options.bypassCache) {
            return cached;
        }
        
        // Check rate limits
        await this.rateLimitManager.waitIfNeeded();
        
        // Add to request queue if needed
        if (this.rateLimitManager.shouldQueue()) {
            return this.requestQueue.add(() => this._makeRequest(endpoint, options));
        }
        
        const response = await this._makeRequest(endpoint, options);
        
        // Cache the response
        await this.cache.set(cacheKey, response, options.cacheTTL || 300);
        
        return response;
    }
    
    async _makeRequest(endpoint, options) {
        const url = `${this.baseUrl}${endpoint}`;
        const headers = {
            'Authorization': `token ${this.token}`,
            'Accept': 'application/vnd.github.v3+json',
            ...options.headers
        };
        
        try {
            const response = await fetch(url, { ...options, headers });
            
            // Update rate limit info
            this.rateLimitManager.updateFromHeaders(response.headers);
            
            if (!response.ok) {
                if (response.status === 403 && response.headers.get('X-RateLimit-Remaining') === '0') {
                    throw new RateLimitError('Rate limit exceeded', this.rateLimitManager.getResetTime());
                }
                throw new APIError(`GitHub API error: ${response.status}`, response.status);
            }
            
            return response.json();
        } catch (error) {
            if (error instanceof RateLimitError) {
                // Handle rate limiting gracefully
                await this.rateLimitManager.handleRateLimit();
                throw error;
            }
            throw error;
        }
    }
    
    async batchRequest(requests) {
        // Use GraphQL for efficient batch requests
        const query = this.buildBatchQuery(requests);
        
        return this.graphqlRequest(query);
    }
    
    async graphqlRequest(query, variables = {}) {
        const cacheKey = this.generateCacheKey('graphql', { query, variables });
        const cached = await this.cache.get(cacheKey);
        
        if (cached) return cached;
        
        await this.rateLimitManager.waitIfNeeded();
        
        const response = await fetch(this.graphqlUrl, {
            method: 'POST',
            headers: {
                'Authorization': `bearer ${this.token}`,
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({ query, variables })
        });
        
        const result = await response.json();
        
        if (result.errors) {
            throw new GraphQLError('GraphQL query failed', result.errors);
        }
        
        await this.cache.set(cacheKey, result.data, 300);
        return result.data;
    }
}
```

### 2. **Rate Limit Manager**

```javascript
class RateLimitManager {
    constructor() {
        this.remaining = 5000;
        this.resetTime = null;
        this.isLimited = false;
        
        // Request queue for when rate limited
        this.queue = [];
        this.processing = false;
    }
    
    updateFromHeaders(headers) {
        this.remaining = parseInt(headers.get('X-RateLimit-Remaining')) || 0;
        this.resetTime = new Date(parseInt(headers.get('X-RateLimit-Reset')) * 1000);
        this.isLimited = this.remaining < 100; // Conservative threshold
    }
    
    async waitIfNeeded() {
        if (this.isLimited && this.resetTime) {
            const waitTime = Math.max(0, this.resetTime.getTime() - Date.now());
            
            if (waitTime > 0) {
                console.log(`Rate limited. Waiting ${waitTime}ms until reset.`);
                await new Promise(resolve => setTimeout(resolve, waitTime));
                this.isLimited = false;
            }
        }
    }
    
    shouldQueue() {
        return this.remaining < 50; // Queue requests when very close to limit
    }
    
    async handleRateLimit() {
        this.isLimited = true;
        
        // Switch to cache-only mode
        this.enableCacheOnlyMode();
        
        // Notify user
        this.notifyUser('Rate limit reached. Switching to cached data.');
    }
    
    enableCacheOnlyMode() {
        // Implementation to force cache-only operations
        window.dispatchEvent(new CustomEvent('github-rate-limited', {
            detail: { resetTime: this.resetTime }
        }));
    }
}
```

### 3. **Multi-Layer Cache**

```javascript
class MultiLayerCache {
    constructor() {
        this.memoryCache = new Map();
        this.storageCache = new StorageCache();
        this.serviceWorkerCache = new ServiceWorkerCache();
        
        this.maxMemoryItems = 1000;
        this.defaultTTL = 300; // 5 minutes
    }
    
    async get(key) {
        // Try memory cache first (fastest)
        if (this.memoryCache.has(key)) {
            const item = this.memoryCache.get(key);
            if (item.expires > Date.now()) {
                return item.data;
            }
            this.memoryCache.delete(key);
        }
        
        // Try localStorage cache
        const stored = await this.storageCache.get(key);
        if (stored) {
            // Promote to memory cache
            this.memoryCache.set(key, {
                data: stored,
                expires: Date.now() + this.defaultTTL * 1000
            });
            return stored;
        }
        
        // Try service worker cache
        const swCached = await this.serviceWorkerCache.get(key);
        if (swCached) {
            // Promote to higher caches
            await this.storageCache.set(key, swCached, this.defaultTTL);
            this.memoryCache.set(key, {
                data: swCached,
                expires: Date.now() + this.defaultTTL * 1000
            });
            return swCached;
        }
        
        return null;
    }
    
    async set(key, data, ttl = this.defaultTTL) {
        const expires = Date.now() + ttl * 1000;
        
        // Set in memory cache
        this.memoryCache.set(key, { data, expires });
        
        // Cleanup memory cache if too large
        if (this.memoryCache.size > this.maxMemoryItems) {
            this.cleanupMemoryCache();
        }
        
        // Set in localStorage cache
        await this.storageCache.set(key, data, ttl);
        
        // Set in service worker cache for offline access
        await this.serviceWorkerCache.set(key, data);
    }
    
    cleanupMemoryCache() {
        // Remove expired items first
        for (const [key, item] of this.memoryCache.entries()) {
            if (item.expires <= Date.now()) {
                this.memoryCache.delete(key);
            }
        }
        
        // If still too large, remove oldest items
        if (this.memoryCache.size > this.maxMemoryItems) {
            const entries = Array.from(this.memoryCache.entries());
            entries.sort((a, b) => a[1].expires - b[1].expires);
            
            const toRemove = entries.slice(0, entries.length - this.maxMemoryItems);
            toRemove.forEach(([key]) => this.memoryCache.delete(key));
        }
    }
}
```

### 4. **Secure Token Manager**

```javascript
class SecureTokenManager {
    constructor() {
        this.clientId = 'your-github-app-client-id';
        this.redirectUri = `${window.location.origin}/auth-callback.html`;
        this.scope = 'repo,user:email,read:org';
        
        this.token = null;
        this.tokenExpiry = null;
        this.refreshToken = null;
        
        // PKCE parameters
        this.codeVerifier = null;
        this.codeChallenge = null;
    }
    
    async initialize() {
        // Try to get existing token
        const stored = this.getStoredTokens();
        
        if (stored && stored.token) {
            this.token = stored.token;
            this.tokenExpiry = new Date(stored.expiry);
            this.refreshToken = stored.refreshToken;
            
            // Validate token
            if (await this.validateToken()) {
                return;
            }
        }
        
        // Need to authenticate
        await this.authenticate();
    }
    
    async authenticate() {
        // Generate PKCE parameters
        this.codeVerifier = this.generateRandomString(128);
        this.codeChallenge = await this.generateCodeChallenge(this.codeVerifier);
        
        const state = this.generateRandomString(32);
        
        // Store PKCE and state
        sessionStorage.setItem('pkce-verifier', this.codeVerifier);
        sessionStorage.setItem('auth-state', state);
        
        const authUrl = `https://github.com/login/oauth/authorize?` +
            `client_id=${this.clientId}&` +
            `redirect_uri=${encodeURIComponent(this.redirectUri)}&` +
            `scope=${encodeURIComponent(this.scope)}&` +
            `state=${state}&` +
            `code_challenge=${this.codeChallenge}&` +
            `code_challenge_method=S256`;
        
        // Open OAuth popup
        const popup = window.open(authUrl, 'github-auth', 'width=600,height=600');
        
        return new Promise((resolve, reject) => {
            const messageHandler = (event) => {
                if (event.origin !== window.location.origin) return;
                
                if (event.data.type === 'github-auth-success') {
                    this.handleAuthSuccess(event.data);
                    window.removeEventListener('message', messageHandler);
                    popup.close();
                    resolve();
                } else if (event.data.type === 'github-auth-error') {
                    window.removeEventListener('message', messageHandler);
                    popup.close();
                    reject(new Error(event.data.error));
                }
            };
            
            window.addEventListener('message', messageHandler);
        });
    }
    
    async handleAuthSuccess(data) {
        // Verify state
        const storedState = sessionStorage.getItem('auth-state');
        if (data.state !== storedState) {
            throw new Error('Invalid state parameter');
        }
        
        // Exchange code for token using PKCE
        const storedVerifier = sessionStorage.getItem('pkce-verifier');
        const token = await this.exchangeCodeForToken(data.code, storedVerifier);
        
        this.token = token.access_token;
        this.refreshToken = token.refresh_token;
        this.tokenExpiry = new Date(Date.now() + token.expires_in * 1000);
        
        // Store securely
        this.storeTokens();
        
        // Cleanup
        sessionStorage.removeItem('pkce-verifier');
        sessionStorage.removeItem('auth-state');
    }
    
    async getValidToken() {
        if (!this.token) {
            await this.initialize();
        }
        
        // Check if token needs refresh
        if (this.tokenExpiry && this.tokenExpiry.getTime() - Date.now() < 300000) { // 5 minutes
            await this.refreshTokenIfNeeded();
        }
        
        return this.token;
    }
    
    async refreshTokenIfNeeded() {
        if (!this.refreshToken) {
            await this.authenticate();
            return;
        }
        
        try {
            const newToken = await this.refreshAccessToken();
            this.token = newToken.access_token;
            this.tokenExpiry = new Date(Date.now() + newToken.expires_in * 1000);
            this.storeTokens();
        } catch (error) {
            console.error('Token refresh failed:', error);
            await this.authenticate();
        }
    }
    
    storeTokens() {
        const tokenData = {
            token: this.token,
            expiry: this.tokenExpiry?.toISOString(),
            refreshToken: this.refreshToken
        };
        
        // Store in encrypted form if possible
        localStorage.setItem('github-tokens', JSON.stringify(tokenData));
    }
    
    getStoredTokens() {
        try {
            const stored = localStorage.getItem('github-tokens');
            return stored ? JSON.parse(stored) : null;
        } catch (error) {
            return null;
        }
    }
    
    generateRandomString(length) {
        const array = new Uint8Array(length);
        crypto.getRandomValues(array);
        return Array.from(array, byte => byte.toString(16).padStart(2, '0')).join('');
    }
    
    async generateCodeChallenge(verifier) {
        const encoder = new TextEncoder();
        const data = encoder.encode(verifier);
        const digest = await crypto.subtle.digest('SHA-256', data);
        return btoa(String.fromCharCode(...new Uint8Array(digest)))
            .replace(/\+/g, '-')
            .replace(/\//g, '_')
            .replace(/=+$/, '');
    }
}
```

## Server-Side Processing via GitHub Actions

### 1. **Enhanced Orchestrator Workflow**

```yaml
name: Enhanced llmXive Orchestrator

on:
  schedule:
    - cron: '*/10 * * * *'  # Every 10 minutes
  workflow_dispatch:
    inputs:
      project_ids:
        description: 'Specific project IDs to process (JSON array)'
        required: false
        default: '[]'
  repository_dispatch:
    types: [dependency-check, project-update]

env:
  NODE_VERSION: '18'
  CACHE_VERSION: 'v1'

jobs:
  prepare:
    runs-on: ubuntu-latest
    outputs:
      projects: ${{ steps.load-projects.outputs.projects }}
      cache-key: ${{ steps.cache-info.outputs.cache-key }}
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive
          lfs: true
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: Generate cache key
        id: cache-info
        run: |
          HASH=$(find projects/ orchestrator/ -type f -name "*.json" -o -name "*.md" | xargs md5sum | md5sum | cut -d' ' -f1)
          echo "cache-key=dependency-cache-${{ env.CACHE_VERSION }}-${HASH}" >> $GITHUB_OUTPUT
      
      - name: Restore dependency cache
        uses: actions/cache@v3
        with:
          path: |
            .dependency-cache/
            .project-registry-cache/
          key: ${{ steps.cache-info.outputs.cache-key }}
          restore-keys: |
            dependency-cache-${{ env.CACHE_VERSION }}-
      
      - name: Load project registry
        id: load-projects
        run: |
          node scripts/enhanced/load-project-registry.js
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  dependency-resolution:
    runs-on: ubuntu-latest
    needs: prepare
    outputs:
      ready-tasks: ${{ steps.resolve-deps.outputs.ready-tasks }}
      blocked-tasks: ${{ steps.resolve-deps.outputs.blocked-tasks }}
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive
          lfs: true
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: Restore dependency cache
        uses: actions/cache@v3
        with:
          path: |
            .dependency-cache/
            .project-registry-cache/
          key: ${{ needs.prepare.outputs.cache-key }}
      
      - name: Resolve dependencies
        id: resolve-deps
        run: |
          node scripts/enhanced/resolve-dependencies.js
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          PROJECT_REGISTRY: ${{ needs.prepare.outputs.projects }}
      
      - name: Update dependency cache
        run: |
          node scripts/enhanced/update-dependency-cache.js
        env:
          READY_TASKS: ${{ steps.resolve-deps.outputs.ready-tasks }}
          BLOCKED_TASKS: ${{ steps.resolve-deps.outputs.blocked-tasks }}

  execute-tasks:
    runs-on: ubuntu-latest
    needs: [prepare, dependency-resolution]
    if: needs.dependency-resolution.outputs.ready-tasks != '[]'
    strategy:
      matrix:
        task: ${{ fromJson(needs.dependency-resolution.outputs.ready-tasks) }}
      max-parallel: 3  # Limit concurrent executions
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive
          lfs: true
          token: ${{ secrets.ADMIN_TOKEN }}
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: Execute task
        id: execute
        run: |
          node scripts/enhanced/execute-task.js
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          TASK_DATA: ${{ toJson(matrix.task) }}
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        timeout-minutes: 30
      
      - name: Handle task failure
        if: failure()
        run: |
          node scripts/enhanced/handle-task-failure.js
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          TASK_DATA: ${{ toJson(matrix.task) }}
          ERROR_INFO: ${{ steps.execute.outputs.error }}
      
      - name: Commit task results
        if: steps.execute.outputs.changes-made == 'true'
        run: |
          git config --local user.email "orchestrator@llmxive.org"
          git config --local user.name "llmXive Orchestrator"
          git add .
          git commit -m "ðŸ¤– Complete task: ${{ matrix.task.taskType }} for ${{ matrix.task.projectId }}"
          git push

  cleanup:
    runs-on: ubuntu-latest
    needs: [prepare, dependency-resolution, execute-tasks]
    if: always()
    steps:
      - uses: actions/checkout@v4
      
      - name: Update project status
        run: |
          node scripts/enhanced/update-project-status.js
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Monitor repository health
        run: |
          node scripts/enhanced/monitor-repo-health.js
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Generate performance report
        run: |
          node scripts/enhanced/generate-performance-report.js
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
```

### 2. **Enhanced Dependency Resolution Script**

```javascript
// scripts/enhanced/resolve-dependencies.js
const { DependencyResolver } = require('./lib/dependency-resolver');
const { ProjectLoader } = require('./lib/project-loader');
const { CacheManager } = require('./lib/cache-manager');

async function main() {
    const cache = new CacheManager('.dependency-cache');
    const loader = new ProjectLoader(process.env.GITHUB_TOKEN);
    const resolver = new DependencyResolver();
    
    try {
        // Load projects from registry
        const projects = JSON.parse(process.env.PROJECT_REGISTRY || '[]');
        
        // Check cache for existing dependency graph
        const cacheKey = `dependency-graph-${projects.map(p => p.id).join('-')}`;
        let dependencyGraph = await cache.get(cacheKey);
        
        if (!dependencyGraph) {
            console.log('Building new dependency graph...');
            dependencyGraph = await resolver.buildDependencyGraph(projects);
            await cache.set(cacheKey, dependencyGraph, 3600); // 1 hour cache
        }
        
        // Resolve ready tasks
        const readyTasks = [];
        const blockedTasks = [];
        
        for (const project of projects) {
            const projectTasks = resolver.getReadyTasks(project.id, dependencyGraph);
            readyTasks.push(...projectTasks);
            
            const projectBlocked = resolver.getBlockingDependencies(project.id, dependencyGraph);
            if (Object.keys(projectBlocked).length > 0) {
                blockedTasks.push({
                    projectId: project.id,
                    blocking: projectBlocked
                });
            }
        }
        
        // Filter by priority and resource availability
        const prioritizedTasks = readyTasks
            .sort((a, b) => b.priority - a.priority)
            .slice(0, 10); // Limit to top 10 tasks
        
        // Output results
        console.log(`Found ${prioritizedTasks.length} ready tasks`);
        console.log(`Found ${blockedTasks.length} projects with blocking dependencies`);
        
        // Set outputs for GitHub Actions
        require('@actions/core').setOutput('ready-tasks', JSON.stringify(prioritizedTasks));
        require('@actions/core').setOutput('blocked-tasks', JSON.stringify(blockedTasks));
        
        // Update cache with results
        await cache.set(`ready-tasks-${Date.now()}`, prioritizedTasks, 600); // 10 minutes
        
    } catch (error) {
        console.error('Dependency resolution failed:', error);
        require('@actions/core').setFailed(error.message);
    }
}

main().catch(error => {
    console.error('Script failed:', error);
    process.exit(1);
});
```

## Service Worker for Offline Support

```javascript
// docs/sw.js
const CACHE_NAME = 'llmxive-v2';
const STATIC_CACHE = 'llmxive-static-v2';
const API_CACHE = 'llmxive-api-v2';

const STATIC_ASSETS = [
    '/',
    '/css/app.css',
    '/js/core/app.js',
    '/js/core/github-client.js',
    '/js/components/project-browser.js',
    '/config/pipeline-stages.json',
    '/config/quality-gates.json'
];

self.addEventListener('install', event => {
    event.waitUntil(
        Promise.all([
            caches.open(STATIC_CACHE).then(cache => cache.addAll(STATIC_ASSETS)),
            caches.open(API_CACHE)
        ])
    );
});

self.addEventListener('fetch', event => {
    const url = new URL(event.request.url);
    
    // Handle GitHub API requests
    if (url.hostname === 'api.github.com') {
        event.respondWith(handleAPIRequest(event.request));
        return;
    }
    
    // Handle static assets
    if (STATIC_ASSETS.includes(url.pathname)) {
        event.respondWith(handleStaticRequest(event.request));
        return;
    }
    
    // Default network-first strategy
    event.respondWith(
        fetch(event.request).catch(() => 
            caches.match(event.request)
        )
    );
});

async function handleAPIRequest(request) {
    const cache = await caches.open(API_CACHE);
    
    try {
        // Try network first
        const response = await fetch(request);
        
        // Cache successful responses
        if (response.ok) {
            cache.put(request, response.clone());
        }
        
        return response;
    } catch (error) {
        // Fallback to cache
        const cached = await cache.match(request);
        
        if (cached) {
            // Add header to indicate cached response
            const newHeaders = new Headers(cached.headers);
            newHeaders.set('X-Served-From', 'cache');
            
            return new Response(cached.body, {
                status: cached.status,
                statusText: cached.statusText,
                headers: newHeaders
            });
        }
        
        throw error;
    }
}

async function handleStaticRequest(request) {
    const cache = await caches.open(STATIC_CACHE);
    
    // Cache first for static assets
    const cached = await cache.match(request);
    if (cached) {
        return cached;
    }
    
    // Fallback to network
    const response = await fetch(request);
    if (response.ok) {
        cache.put(request, response.clone());
    }
    
    return response;
}
```

## Performance Monitoring and Health Checks

### 1. **Repository Health Monitor**

```javascript
// scripts/enhanced/monitor-repo-health.js
const { Octokit } = require('@octokit/rest');

class RepositoryHealthMonitor {
    constructor(token) {
        this.octokit = new Octokit({ auth: token });
        this.org = 'ContextLab';
        this.repo = 'llmXive';
    }
    
    async checkHealth() {
        const health = {
            repository: await this.checkRepositoryHealth(),
            lfs: await this.checkLFSUsage(),
            actions: await this.checkActionsUsage(),
            api: await this.checkAPIUsage(),
            projects: await this.checkProjectHealth()
        };
        
        const issues = this.identifyIssues(health);
        
        if (issues.length > 0) {
            await this.createHealthReport(health, issues);
        }
        
        return health;
    }
    
    async checkRepositoryHealth() {
        const { data: repo } = await this.octokit.repos.get({
            owner: this.org,
            repo: this.repo
        });
        
        return {
            size: repo.size,
            sizeLimit: 1000000, // 1GB in KB
            utilizationPercent: (repo.size / 1000000) * 100,
            isHealthy: repo.size < 800000 // Alert at 80%
        };
    }
    
    async checkLFSUsage() {
        // Check Git LFS usage
        try {
            const { data: lfsObjects } = await this.octokit.repos.getLFSObjects({
                owner: this.org,
                repo: this.repo
            });
            
            const totalSize = lfsObjects.reduce((sum, obj) => sum + obj.size, 0);
            
            return {
                objectCount: lfsObjects.length,
                totalSize: totalSize,
                sizeLimit: 1073741824, // 1GB
                utilizationPercent: (totalSize / 1073741824) * 100,
                isHealthy: totalSize < 858993459 // Alert at 80%
            };
        } catch (error) {
            return {
                error: error.message,
                isHealthy: false
            };
        }
    }
    
    async checkActionsUsage() {
        const { data: billing } = await this.octokit.billing.getGitHubActionsBillingOrg({
            org: this.org
        });
        
        return {
            minutesUsed: billing.total_minutes_used,
            minutesLimit: billing.included_minutes,
            utilizationPercent: (billing.total_minutes_used / billing.included_minutes) * 100,
            isHealthy: billing.total_minutes_used < billing.included_minutes * 0.8
        };
    }
    
    async checkAPIUsage() {
        // Check rate limit status
        const { data: rateLimit } = await this.octokit.rateLimit.get();
        
        return {
            core: {
                remaining: rateLimit.core.remaining,
                limit: rateLimit.core.limit,
                resetTime: new Date(rateLimit.core.reset * 1000),
                isHealthy: rateLimit.core.remaining > rateLimit.core.limit * 0.1
            },
            graphql: {
                remaining: rateLimit.graphql.remaining,
                limit: rateLimit.graphql.limit,
                resetTime: new Date(rateLimit.graphql.reset * 1000),
                isHealthy: rateLimit.graphql.remaining > rateLimit.graphql.limit * 0.1
            }
        };
    }
    
    async checkProjectHealth() {
        // Load and analyze project health
        const projects = await this.loadAllProjects();
        
        const health = {
            totalProjects: projects.length,
            activeProjects: projects.filter(p => p.status === 'in_progress').length,
            completedProjects: projects.filter(p => p.status === 'completed').length,
            stalledProjects: [],
            oversizeProjects: []
        };
        
        for (const project of projects) {
            // Check for stalled projects
            const lastActivity = new Date(project.lastUpdated);
            const daysSinceActivity = (Date.now() - lastActivity.getTime()) / (1000 * 60 * 60 * 24);
            
            if (daysSinceActivity > 30 && project.status === 'in_progress') {
                health.stalledProjects.push({
                    id: project.id,
                    daysSinceActivity: Math.floor(daysSinceActivity)
                });
            }
            
            // Check for oversize projects
            if (project.size > 500 * 1024 * 1024) { // 500MB
                health.oversizeProjects.push({
                    id: project.id,
                    size: project.size,
                    shouldConsiderSplit: project.size > 1024 * 1024 * 1024 // 1GB
                });
            }
        }
        
        return health;
    }
    
    identifyIssues(health) {
        const issues = [];
        
        if (!health.repository.isHealthy) {
            issues.push({
                type: 'repository_size',
                severity: 'warning',
                message: `Repository size is ${health.repository.utilizationPercent.toFixed(1)}% of limit`
            });
        }
        
        if (health.lfs && !health.lfs.isHealthy) {
            issues.push({
                type: 'lfs_usage',
                severity: 'warning',
                message: `Git LFS usage is ${health.lfs.utilizationPercent?.toFixed(1) || 'unknown'}% of limit`
            });
        }
        
        if (!health.actions.isHealthy) {
            issues.push({
                type: 'actions_usage',
                severity: 'critical',
                message: `GitHub Actions usage is ${health.actions.utilizationPercent.toFixed(1)}% of limit`
            });
        }
        
        if (!health.api.core.isHealthy || !health.api.graphql.isHealthy) {
            issues.push({
                type: 'api_limits',
                severity: 'critical',
                message: 'GitHub API rate limits are being exceeded'
            });
        }
        
        if (health.projects.stalledProjects.length > 5) {
            issues.push({
                type: 'stalled_projects',
                severity: 'warning',
                message: `${health.projects.stalledProjects.length} projects appear to be stalled`
            });
        }
        
        return issues;
    }
    
    async createHealthReport(health, issues) {
        const report = {
            timestamp: new Date().toISOString(),
            health,
            issues,
            recommendations: this.generateRecommendations(issues)
        };
        
        // Save report as GitHub release
        const reportContent = JSON.stringify(report, null, 2);
        
        await this.octokit.repos.createRelease({
            owner: this.org,
            repo: this.repo,
            tag_name: `health-report-${Date.now()}`,
            name: `Health Report - ${new Date().toLocaleDateString()}`,
            body: this.generateHealthSummary(health, issues),
            draft: false,
            prerelease: true
        });
        
        // Also create issue if critical problems found
        const criticalIssues = issues.filter(i => i.severity === 'critical');
        if (criticalIssues.length > 0) {
            await this.createHealthIssue(criticalIssues);
        }
    }
}
```

## Conclusion

This improved architecture addresses the critical concerns identified in the expert review:

### âœ… **Fixed Issues**
1. **Rate Limiting**: Robust multi-layer caching and intelligent request batching
2. **Repository Management**: Git LFS first approach with simplified splitting logic
3. **Security**: Proper OAuth PKCE flow with secure token management
4. **Performance**: Server-side dependency resolution and offline capability
5. **Error Handling**: Comprehensive error recovery and graceful degradation

### âœ… **Enhanced Features**
1. **Offline Support**: Service worker with intelligent caching
2. **Performance Monitoring**: Real-time health checks and reporting
3. **Scalability**: Efficient GraphQL usage and background processing
4. **Maintainability**: Clear separation of concerns and robust error handling

### âœ… **Production Ready**
- Comprehensive testing and validation
- Security best practices
- Performance optimization
- Monitoring and alerting
- Documentation and maintenance procedures

This architecture provides a robust, scalable, and maintainable foundation for llmXive v2.0 that can grow from small projects to massive research endeavors while remaining completely free to host and operate.